[Info] output_dir:	runs/S1413_ESM2_Baseline	<class 'str'>
[Info] loss_fn_name:	L1	<class 'str'>
[Info] learning rate:	0.005	<class 'float'>
[Info] seeds:	[10, 11, 12]	<class 'list'>
[Info] max_epochs:	20	<class 'int'>
[Info] model_name:	ESM2_Baseline	<class 'str'>
[Info] optimizer_name:	AdamW	<class 'str'>
[Info] train_dir:	datasets/S1413/train	<class 'str'>
[Info] val_dir:	datasets/S1413/validation	<class 'str'>
[Info] test_dir:	datasets/S1413/test	<class 'str'>
[Info] max_length:	1024	<class 'int'>
[Info] Total time for Finetuning: 0:10:35.594726 on 64 GPUs
[Info] Max GPU memory reserved for Finetuning: 5133.0 MB
[Info] Max GPU memory allocated for Finetuning: 3206.0 MB
[Info] Total GPU memory for Finetuning: 68099.0 MB
