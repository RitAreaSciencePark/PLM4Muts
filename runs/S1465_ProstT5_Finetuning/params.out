[Info] output_dir:	runs/S1465_ProstT5_Finetuning	<class 'str'>
[Info] loss_fn_name:	L1	<class 'str'>
[Info] learning rate:	0.001	<class 'float'>
[Info] seeds:	[10, 11, 12]	<class 'list'>
[Info] max_epochs:	20	<class 'int'>
[Info] model_name:	ProstT5_Finetuning	<class 'str'>
[Info] optimizer_name:	AdamW	<class 'str'>
[Info] train_dir:	datasets/S1465/train	<class 'str'>
[Info] val_dir:	datasets/S1465/validation	<class 'str'>
[Info] test_dir:	datasets/S1465/test	<class 'str'>
[Info] max_length:	490	<class 'int'>
[Info] Total time for Finetuning: 0:18:41.557725 on 64 GPUs
[Info] Max GPU memory reserved for Finetuning: 37232.0 MB
[Info] Max GPU memory allocated for Finetuning: 32168.0 MB
[Info] Total GPU memory for Finetuning: 68099.0 MB
