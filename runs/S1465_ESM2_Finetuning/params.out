[Info] output_dir:	runs/S1465_ESM2_Finetuning	<class 'str'>
[Info] loss_fn_name:	L1	<class 'str'>
[Info] learning rate:	0.005	<class 'float'>
[Info] seeds:	[10, 11, 12]	<class 'list'>
[Info] max_epochs:	20	<class 'int'>
[Info] model_name:	ESM2_Finetuning	<class 'str'>
[Info] optimizer_name:	AdamW	<class 'str'>
[Info] train_dir:	datasets/S1465/train	<class 'str'>
[Info] val_dir:	datasets/S1465/validation	<class 'str'>
[Info] test_dir:	datasets/S1465/test	<class 'str'>
[Info] max_length:	1024	<class 'int'>
[Info] Total time for Finetuning: 0:08:02.444136 on 64 GPUs
[Info] Max GPU memory reserved for Finetuning: 21032.0 MB
[Info] Max GPU memory allocated for Finetuning: 19111.0 MB
[Info] Total GPU memory for Finetuning: 68099.0 MB
